# LCS-001: LLMConsent Core Standard

**Version**: 0.1.0  
**Status**: Draft  
**Created**: 2025-08-12  
**Authors**: Subhadip Mitra

## Abstract

This standard defines a decentralized protocol for managing consent between humans and AI systems. It establishes cryptographically-verifiable permissions for data usage in training, inference, and agent actions, ensuring no single entity controls the consent layer of AI interactions.

## Motivation

Current AI systems lack a standardized way to:
- Obtain verifiable consent for training data usage
- Track data attribution in model outputs
- Manage permissions for agent actions
- Compensate data providers
- Enable data sovereignty in AI interactions

This standard creates an open, interoperable protocol that any AI system can implement.

## Specification

### 1. Consent Token Structure

Every consent token MUST contain:

```solidity
struct ConsentToken {
    // Identity
    uint256 tokenId;
    address owner;
    
    // Permissions
    uint8 permissions;  // Bitmask: TRAIN=1, INFER=2, AGENT=4, MEMORY=8
    
    // Scope
    bytes32[] modelIds;     // Which models can use this
    bytes32[] purposes;     // Hash of allowed purposes
    
    // Constraints  
    uint256 maxInfluence;   // Basis points (100 = 1%)
    uint256 expiresAt;
    
    // Economics
    uint256 trainingRate;   // Per epoch
    uint256 inferenceRate;  // Per 1k tokens
    
    // Control
    bool revocable;
    bool unlearningEnabled;
}
```

### 2. Core Operations

All implementations MUST support:

#### 2.1 Grant Consent
```solidity
function grantConsent(
    bytes32 dataHash,
    uint8 permissions,
    uint256 duration
) returns (uint256 tokenId)
```

#### 2.2 Check Consent
```solidity
function checkConsent(
    address user,
    bytes32 dataHash,
    uint8 requestedPermission
) returns (bool allowed, uint256 rate)
```

#### 2.3 Revoke Consent  
```solidity
function revokeConsent(uint256 tokenId)
```

### 3. Agent Interaction Protocol

Agents MUST follow this flow:

```
1. Agent requests permission via `requestConsent()`
2. User grants/denies via `grantConsent()` 
3. Agent checks permission via `checkConsent()`
4. Agent logs usage via `logUsage()`
5. Protocol distributes compensation via `distribute()`
```

### 4. Digital Twin Registry

Optional extension for persistent user models:

```solidity
interface IDigitalTwin {
    function registerTwin(bytes32 modelHash) returns (uint256);
    function updateTwin(uint256 twinId, bytes32 newModelHash);
    function grantAccess(uint256 twinId, address agent, uint8 permissions);
    function getAccess(uint256 twinId, address agent) returns (uint8);
}
```

### 5. Attribution Requirements

Systems claiming compliance MUST:
- Track which training data influenced outputs
- Provide proof of influence (ZK-proof or equivalent)
- Support challenge/verification of claims

### 6. Decentralization Requirements

- No single admin key
- No ability to freeze or seize tokens
- Upgrades only via DAO governance (>50% vote)
- Multiple independent implementations

## Implementation

### Reference Implementation

The reference implementation provides:
- Solidity smart contracts (Ethereum/EVM)
- Python SDK
- TypeScript SDK  
- Test suite

### Compliance Testing

Implementations MUST pass:
- Core functionality tests
- Gas efficiency benchmarks (<100k for consent check)
- Security audits
- Decentralization verification

## Rationale

**Why blockchain?** Provides decentralized, immutable record of consent without central authority.

**Why token-based?** Enables composability, transferability, and standard interfaces.

**Why include compensation?** Aligns incentives for data sharing in AI development.

**Why attribution tracking?** Enables accountability and regulatory compliance.

## Security Considerations

- Private keys control consent tokens
- Lost keys mean lost consent control
- Smart contract bugs are permanent
- ZK-proofs prevent data leakage

## Copyright

This standard is released under CC0 - No Rights Reserved.

## Citation

```
LCS-001: LLMConsent Core Standard. (2025). 
LLMConsent Foundation. https://llmconsent.org/standards/LCS-001
```